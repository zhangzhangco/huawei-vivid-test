#!/usr/bin/env python3
"""
è‡ªåŠ¨åŒ–å›å½’æµ‹è¯•å¥—ä»¶
é›†æˆæ‰€æœ‰éªŒè¯æµ‹è¯•ï¼Œæä¾›å®Œæ•´çš„å›å½’æµ‹è¯•åŠŸèƒ½
"""

import pytest
import numpy as np
import os
import tempfile
import json
from pathlib import Path
from typing import Dict, List, Any
import sys

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from test_validation_framework import (
    AutomatedRegressionTestSuite, ValidationResult,
    GoldenStandardTests, MonotonicityStressTests, 
    HysteresisStabilityTests, ExportImportConsistencyTests
)
from golden_test_data import GoldenTestDataGenerator


class TestRegressionSuite:
    """å›å½’æµ‹è¯•å¥—ä»¶æµ‹è¯•ç±»"""
    
    @classmethod
    def setup_class(cls):
        """ç±»çº§åˆ«è®¾ç½®"""
        cls.test_suite = AutomatedRegressionTestSuite()
        cls.temp_dir = tempfile.mkdtemp()
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        cls.data_generator = GoldenTestDataGenerator()
        cls.golden_images = cls.data_generator.generate_golden_images()
        cls.golden_curves = cls.data_generator.generate_golden_curves()
        
    @classmethod
    def teardown_class(cls):
        """ç±»çº§åˆ«æ¸…ç†"""
        import shutil
        if hasattr(cls, 'temp_dir') and os.path.exists(cls.temp_dir):
            shutil.rmtree(cls.temp_dir, ignore_errors=True)
            
    def test_golden_standard_phoenix_curves(self):
        """æµ‹è¯•Phoenixæ›²çº¿é‡‘æ ‡æµ‹è¯•"""
        golden_tests = GoldenStandardTests()
        results = golden_tests.run_golden_tests()
        
        # ç­›é€‰Phoenixæ›²çº¿æµ‹è¯•
        phoenix_results = [r for r in results if r.test_name.startswith("phoenix_")]
        
        assert len(phoenix_results) > 0, "åº”è¯¥æœ‰Phoenixæ›²çº¿æµ‹è¯•"
        
        # æ£€æŸ¥åŸºç¡€æµ‹è¯•é€šè¿‡
        basic_tests = [r for r in phoenix_results if "basic" in r.test_name or "gamma22" in r.test_name]
        for test in basic_tests:
            assert test.passed, f"åŸºç¡€Phoenixæµ‹è¯•å¤±è´¥: {test.test_name} - {test.error_message}"
            
        # ç»Ÿè®¡é€šè¿‡ç‡
        passed_count = sum(1 for r in phoenix_results if r.passed)
        total_count = len(phoenix_results)
        pass_rate = passed_count / total_count
        
        print(f"Phoenixæ›²çº¿æµ‹è¯•é€šè¿‡ç‡: {passed_count}/{total_count} ({pass_rate*100:.1f}%)")
        
        # è‡³å°‘80%çš„æµ‹è¯•åº”è¯¥é€šè¿‡
        assert pass_rate >= 0.8, f"Phoenixæ›²çº¿æµ‹è¯•é€šè¿‡ç‡è¿‡ä½: {pass_rate*100:.1f}%"
        
    def test_golden_standard_quality_metrics(self):
        """æµ‹è¯•è´¨é‡æŒ‡æ ‡é‡‘æ ‡æµ‹è¯•"""
        golden_tests = GoldenStandardTests()
        results = golden_tests.run_golden_tests()
        
        # ç­›é€‰è´¨é‡æŒ‡æ ‡æµ‹è¯•
        quality_results = [r for r in results if r.test_name.startswith("quality_")]
        
        assert len(quality_results) > 0, "åº”è¯¥æœ‰è´¨é‡æŒ‡æ ‡æµ‹è¯•"
        
        # å‡åŒ€å›¾åƒæµ‹è¯•åº”è¯¥é€šè¿‡
        uniform_test = next((r for r in quality_results if "uniform" in r.test_name), None)
        if uniform_test:
            assert uniform_test.passed, f"å‡åŒ€å›¾åƒè´¨é‡æŒ‡æ ‡æµ‹è¯•å¤±è´¥: {uniform_test.error_message}"
            
            # æ£€æŸ¥å…·ä½“æŒ‡æ ‡å€¼
            if uniform_test.actual_values:
                assert uniform_test.actual_values.get("perceptual_distortion", 1.0) < 1e-6
                assert uniform_test.actual_values.get("local_contrast", 1.0) < 1e-6
                assert uniform_test.actual_values.get("variance_distortion", 1.0) < 1e-6
                
    def test_golden_standard_temporal_smoothing(self):
        """æµ‹è¯•æ—¶åŸŸå¹³æ»‘é‡‘æ ‡æµ‹è¯•"""
        golden_tests = GoldenStandardTests()
        results = golden_tests.run_golden_tests()
        
        # ç­›é€‰æ—¶åŸŸå¹³æ»‘æµ‹è¯•
        temporal_results = [r for r in results if r.test_name.startswith("temporal_")]
        
        assert len(temporal_results) > 0, "åº”è¯¥æœ‰æ—¶åŸŸå¹³æ»‘æµ‹è¯•"
        
        # æ’å®šå‚æ•°æµ‹è¯•åº”è¯¥é€šè¿‡
        constant_test = next((r for r in temporal_results if "constant" in r.test_name), None)
        if constant_test:
            assert constant_test.passed, f"æ’å®šå‚æ•°æ—¶åŸŸå¹³æ»‘æµ‹è¯•å¤±è´¥: {constant_test.error_message}"
            
    def test_monotonicity_stress_comprehensive(self):
        """æµ‹è¯•å…¨é¢çš„å•è°ƒæ€§å‹åŠ›æµ‹è¯•"""
        mono_tests = MonotonicityStressTests()
        results = mono_tests.run_monotonicity_stress_tests()
        
        assert len(results) > 0, "åº”è¯¥æœ‰å•è°ƒæ€§å‹åŠ›æµ‹è¯•ç»“æœ"
        
        # æ£€æŸ¥Phoenixå•è°ƒæ€§å‹åŠ›æµ‹è¯•
        phoenix_stress = next((r for r in results if "phoenix_monotonicity_stress" in r.test_name), None)
        assert phoenix_stress is not None, "åº”è¯¥æœ‰Phoenixå•è°ƒæ€§å‹åŠ›æµ‹è¯•"
        
        if not phoenix_stress.passed:
            print(f"Phoenixå•è°ƒæ€§å‹åŠ›æµ‹è¯•å¤±è´¥: {phoenix_stress.error_message}")
            if phoenix_stress.actual_values and "failed_combinations" in phoenix_stress.actual_values:
                failed = phoenix_stress.actual_values["failed_combinations"]
                print(f"å¤±è´¥çš„å‚æ•°ç»„åˆ: {failed[:5]}...")  # åªæ˜¾ç¤ºå‰5ä¸ª
                
        # æ£€æŸ¥æ ·æ¡å•è°ƒæ€§å‹åŠ›æµ‹è¯•
        spline_stress = next((r for r in results if "spline_monotonicity_stress" in r.test_name), None)
        if spline_stress:
            if not spline_stress.passed:
                print(f"æ ·æ¡å•è°ƒæ€§å‹åŠ›æµ‹è¯•å¤±è´¥: {spline_stress.error_message}")
                
        # æ£€æŸ¥æç«¯å‚æ•°æµ‹è¯•
        extreme_results = [r for r in results if "extreme_monotonicity" in r.test_name]
        extreme_passed = sum(1 for r in extreme_results if r.passed)
        extreme_total = len(extreme_results)
        
        if extreme_total > 0:
            extreme_pass_rate = extreme_passed / extreme_total
            print(f"æç«¯å‚æ•°å•è°ƒæ€§æµ‹è¯•é€šè¿‡ç‡: {extreme_passed}/{extreme_total} ({extreme_pass_rate*100:.1f}%)")
            
            # è‡³å°‘70%çš„æç«¯å‚æ•°æµ‹è¯•åº”è¯¥é€šè¿‡
            assert extreme_pass_rate >= 0.7, f"æç«¯å‚æ•°å•è°ƒæ€§æµ‹è¯•é€šè¿‡ç‡è¿‡ä½: {extreme_pass_rate*100:.1f}%"
            
    def test_hysteresis_stability_comprehensive(self):
        """æµ‹è¯•å…¨é¢çš„æ»å›ç¨³å®šæ€§æµ‹è¯•"""
        hysteresis_tests = HysteresisStabilityTests()
        results = hysteresis_tests.run_hysteresis_stability_tests()
        
        assert len(results) > 0, "åº”è¯¥æœ‰æ»å›ç¨³å®šæ€§æµ‹è¯•ç»“æœ"
        
        # åŸºæœ¬æ»å›æµ‹è¯•å¿…é¡»é€šè¿‡
        basic_test = next((r for r in results if "basic_hysteresis" in r.test_name), None)
        assert basic_test is not None, "åº”è¯¥æœ‰åŸºæœ¬æ»å›æµ‹è¯•"
        assert basic_test.passed, f"åŸºæœ¬æ»å›æµ‹è¯•å¤±è´¥: {basic_test.error_message}"
        
        # è¾¹ç•ŒæŒ¯è¡æµ‹è¯•
        oscillation_test = next((r for r in results if "boundary_oscillation" in r.test_name), None)
        if oscillation_test:
            if not oscillation_test.passed:
                print(f"è¾¹ç•ŒæŒ¯è¡æµ‹è¯•å¤±è´¥: {oscillation_test.error_message}")
            else:
                print("è¾¹ç•ŒæŒ¯è¡æµ‹è¯•é€šè¿‡")
                
        # é•¿æœŸç¨³å®šæ€§æµ‹è¯•
        stability_test = next((r for r in results if "long_term_stability" in r.test_name), None)
        if stability_test:
            if not stability_test.passed:
                print(f"é•¿æœŸç¨³å®šæ€§æµ‹è¯•å¤±è´¥: {stability_test.error_message}")
            else:
                print("é•¿æœŸç¨³å®šæ€§æµ‹è¯•é€šè¿‡")
                
        # è‡³å°‘åŸºæœ¬æµ‹è¯•å¿…é¡»é€šè¿‡
        critical_tests = [basic_test]
        critical_passed = sum(1 for t in critical_tests if t and t.passed)
        assert critical_passed == len(critical_tests), "å…³é”®æ»å›æµ‹è¯•å¿…é¡»å…¨éƒ¨é€šè¿‡"
        
    def test_export_import_consistency_comprehensive(self):
        """æµ‹è¯•å…¨é¢çš„å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§æµ‹è¯•"""
        consistency_tests = ExportImportConsistencyTests()
        results = consistency_tests.run_consistency_tests()
        
        assert len(results) > 0, "åº”è¯¥æœ‰ä¸€è‡´æ€§æµ‹è¯•ç»“æœ"
        
        # LUTä¸€è‡´æ€§æµ‹è¯•
        lut_test = next((r for r in results if "lut_consistency" in r.test_name), None)
        assert lut_test is not None, "åº”è¯¥æœ‰LUTä¸€è‡´æ€§æµ‹è¯•"
        
        if not lut_test.passed:
            print(f"LUTä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {lut_test.error_message}")
            if lut_test.actual_values:
                max_error = lut_test.actual_values.get("max_error", "æœªçŸ¥")
                print(f"LUTæœ€å¤§è¯¯å·®: {max_error}")
        else:
            print("LUTä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
            
        # CSVä¸€è‡´æ€§æµ‹è¯•
        csv_test = next((r for r in results if "csv_consistency" in r.test_name), None)
        if csv_test:
            if not csv_test.passed:
                print(f"CSVä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {csv_test.error_message}")
            else:
                print("CSVä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
                
        # è¯Šæ–­åŒ…å®Œæ•´æ€§æµ‹è¯•
        diagnostic_test = next((r for r in results if "diagnostic_package" in r.test_name), None)
        if diagnostic_test:
            if not diagnostic_test.passed:
                print(f"è¯Šæ–­åŒ…å®Œæ•´æ€§æµ‹è¯•å¤±è´¥: {diagnostic_test.error_message}")
            else:
                print("è¯Šæ–­åŒ…å®Œæ•´æ€§æµ‹è¯•é€šè¿‡")
                
        # ä¼šè¯çŠ¶æ€ä¸€è‡´æ€§æµ‹è¯•
        session_test = next((r for r in results if "session_state" in r.test_name), None)
        if session_test:
            if not session_test.passed:
                print(f"ä¼šè¯çŠ¶æ€ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {session_test.error_message}")
            else:
                print("ä¼šè¯çŠ¶æ€ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
                
        # ç»Ÿè®¡é€šè¿‡ç‡
        passed_count = sum(1 for r in results if r.passed)
        total_count = len(results)
        pass_rate = passed_count / total_count
        
        print(f"å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ç‡: {passed_count}/{total_count} ({pass_rate*100:.1f}%)")
        
        # è‡³å°‘90%çš„ä¸€è‡´æ€§æµ‹è¯•åº”è¯¥é€šè¿‡
        assert pass_rate >= 0.9, f"å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡ç‡è¿‡ä½: {pass_rate*100:.1f}%"
        
    def test_full_regression_suite_execution(self):
        """æµ‹è¯•å®Œæ•´å›å½’æµ‹è¯•å¥—ä»¶æ‰§è¡Œ"""
        results = self.test_suite.run_full_regression_suite()
        
        # æ£€æŸ¥ç»“æœç»“æ„å®Œæ•´æ€§
        required_keys = [
            "test_summary",
            "golden_standard_tests", 
            "monotonicity_stress_tests",
            "hysteresis_stability_tests",
            "export_import_consistency_tests",
            "detailed_failures"
        ]
        
        for key in required_keys:
            assert key in results, f"ç»“æœä¸­ç¼ºå°‘å¿…éœ€çš„é”®: {key}"
            
        # æ£€æŸ¥æµ‹è¯•æ‘˜è¦
        summary = results["test_summary"]
        assert "total_tests" in summary
        assert "passed_tests" in summary
        assert "failed_tests" in summary
        assert "start_time" in summary
        assert "end_time" in summary
        
        # éªŒè¯æµ‹è¯•æ•°é‡ä¸€è‡´æ€§
        total_from_categories = (
            len(results["golden_standard_tests"]) +
            len(results["monotonicity_stress_tests"]) +
            len(results["hysteresis_stability_tests"]) +
            len(results["export_import_consistency_tests"])
        )
        
        assert summary["total_tests"] == total_from_categories, "æµ‹è¯•æ€»æ•°ä¸ä¸€è‡´"
        assert summary["total_tests"] == summary["passed_tests"] + summary["failed_tests"], "é€šè¿‡å’Œå¤±è´¥æµ‹è¯•æ•°é‡ä¸åŒ¹é…"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•æ‰§è¡Œ
        assert summary["total_tests"] > 0, "åº”è¯¥æœ‰æµ‹è¯•æ‰§è¡Œ"
        
        # æ‰“å°æµ‹è¯•æ‘˜è¦
        print(f"\n=== å›å½’æµ‹è¯•å¥—ä»¶æ‰§è¡Œæ‘˜è¦ ===")
        print(f"æ€»æµ‹è¯•æ•°: {summary['total_tests']}")
        print(f"é€šè¿‡: {summary['passed_tests']}")
        print(f"å¤±è´¥: {summary['failed_tests']}")
        print(f"é€šè¿‡ç‡: {summary['passed_tests']/summary['total_tests']*100:.1f}%")
        
        # å¦‚æœæœ‰å¤±è´¥ï¼Œæ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
        if summary["failed_tests"] > 0:
            print(f"\n=== å¤±è´¥æµ‹è¯•è¯¦æƒ… ===")
            for failure in results["detailed_failures"][:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                print(f"- {failure['test_name']}: {failure['error_message']}")
                
        # å„ç±»æµ‹è¯•é€šè¿‡ç‡
        categories = [
            ("golden_standard_tests", "é‡‘æ ‡æµ‹è¯•"),
            ("monotonicity_stress_tests", "å•è°ƒæ€§å‹åŠ›æµ‹è¯•"),
            ("hysteresis_stability_tests", "æ»å›ç¨³å®šæ€§æµ‹è¯•"),
            ("export_import_consistency_tests", "å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§æµ‹è¯•")
        ]
        
        print(f"\n=== å„ç±»æµ‹è¯•é€šè¿‡ç‡ ===")
        for category_key, category_name in categories:
            category_results = results[category_key]
            if category_results:
                passed = sum(1 for r in category_results if r.passed)
                total = len(category_results)
                rate = passed / total * 100
                print(f"{category_name}: {passed}/{total} ({rate:.1f}%)")
                
    def test_report_generation_and_content(self):
        """æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå’Œå†…å®¹"""
        results = self.test_suite.run_full_regression_suite()
        
        # ç”ŸæˆæŠ¥å‘Š
        report_file = os.path.join(self.temp_dir, "test_report.md")
        report_content = self.test_suite.generate_test_report(results, report_file)
        
        # æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶ç”Ÿæˆ
        assert os.path.exists(report_file), "æŠ¥å‘Šæ–‡ä»¶åº”è¯¥è¢«åˆ›å»º"
        
        # æ£€æŸ¥æŠ¥å‘Šå†…å®¹
        assert "HDRè‰²è°ƒæ˜ å°„ä¸“åˆ©å¯è§†åŒ–å·¥å…·éªŒè¯æŠ¥å‘Š" in report_content
        assert "æµ‹è¯•æ‘˜è¦" in report_content
        assert "é€šè¿‡ç‡" in report_content
        
        # æ£€æŸ¥å„ç±»æµ‹è¯•åœ¨æŠ¥å‘Šä¸­
        test_categories = ["é‡‘æ ‡æµ‹è¯•ç”¨ä¾‹", "å•è°ƒæ€§å‹åŠ›æµ‹è¯•", "æ»å›ç¨³å®šæ€§æµ‹è¯•", "å¯¼å‡º/å¯¼å…¥ä¸€è‡´æ€§æµ‹è¯•"]
        for category in test_categories:
            assert category in report_content, f"æŠ¥å‘Šä¸­åº”è¯¥åŒ…å«{category}"
            
        # æ£€æŸ¥æŠ¥å‘Šæ–‡ä»¶å†…å®¹ä¸è¿”å›å†…å®¹ä¸€è‡´
        with open(report_file, 'r', encoding='utf-8') as f:
            file_content = f.read()
            
        assert file_content == report_content, "æ–‡ä»¶å†…å®¹åº”è¯¥ä¸è¿”å›å†…å®¹ä¸€è‡´"
        
        print(f"æµ‹è¯•æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        print(f"æŠ¥å‘Šé•¿åº¦: {len(report_content)} å­—ç¬¦")
        
    def test_performance_benchmarks(self):
        """æµ‹è¯•æ€§èƒ½åŸºå‡†"""
        import time
        
        # æµ‹è¯•å•ä¸ªPhoenixæ›²çº¿è®¡ç®—æ€§èƒ½
        from core import PhoenixCurveCalculator
        
        calc = PhoenixCurveCalculator()
        L = np.linspace(0, 1, 1000)
        
        start_time = time.time()
        for _ in range(100):  # 100æ¬¡è®¡ç®—
            calc.compute_phoenix_curve(L, 2.0, 0.5)
        end_time = time.time()
        
        avg_time_ms = (end_time - start_time) / 100 * 1000
        print(f"Phoenixæ›²çº¿è®¡ç®—å¹³å‡æ—¶é—´: {avg_time_ms:.2f} ms")
        
        # æ€§èƒ½è¦æ±‚: å•æ¬¡è®¡ç®—åº”è¯¥åœ¨10msä»¥å†…
        assert avg_time_ms < 10.0, f"Phoenixæ›²çº¿è®¡ç®—æ€§èƒ½ä¸è¾¾æ ‡: {avg_time_ms:.2f} ms > 10 ms"
        
        # æµ‹è¯•è´¨é‡æŒ‡æ ‡è®¡ç®—æ€§èƒ½
        from core import QualityMetricsCalculator
        
        quality_calc = QualityMetricsCalculator()
        test_image = np.random.rand(256, 256).astype(np.float32)
        L_in = quality_calc.extract_luminance(test_image)
        L_out = L_in ** 2.0
        
        start_time = time.time()
        for _ in range(50):  # 50æ¬¡è®¡ç®—
            quality_calc.compute_all_metrics(L_in, L_out)
        end_time = time.time()
        
        avg_time_ms = (end_time - start_time) / 50 * 1000
        print(f"è´¨é‡æŒ‡æ ‡è®¡ç®—å¹³å‡æ—¶é—´: {avg_time_ms:.2f} ms")
        
        # æ€§èƒ½è¦æ±‚: è´¨é‡æŒ‡æ ‡è®¡ç®—åº”è¯¥åœ¨50msä»¥å†…
        assert avg_time_ms < 50.0, f"è´¨é‡æŒ‡æ ‡è®¡ç®—æ€§èƒ½ä¸è¾¾æ ‡: {avg_time_ms:.2f} ms > 50 ms"
        
    def test_memory_usage_validation(self):
        """æµ‹è¯•å†…å­˜ä½¿ç”¨éªŒè¯"""
        import psutil
        import gc
        
        # è·å–åˆå§‹å†…å­˜ä½¿ç”¨
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # æ‰§è¡Œå¤§é‡è®¡ç®—
        from core import PhoenixCurveCalculator, QualityMetricsCalculator
        
        calc = PhoenixCurveCalculator()
        quality_calc = QualityMetricsCalculator()
        
        # åˆ›å»ºå¤§é‡æ•°æ®
        large_arrays = []
        for i in range(10):
            L = np.linspace(0, 1, 10000)
            L_out = calc.compute_phoenix_curve(L, 2.0 + i * 0.1, 0.5)
            large_arrays.append(L_out)
            
            # åˆ›å»ºå¤§å›¾åƒ
            large_image = np.random.rand(512, 512).astype(np.float32)
            L_in = quality_calc.extract_luminance(large_image)
            quality_calc.compute_all_metrics(L_in, L_out[:512*512])
            
        # æ£€æŸ¥å†…å­˜ä½¿ç”¨
        peak_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = peak_memory - initial_memory
        
        print(f"åˆå§‹å†…å­˜: {initial_memory:.1f} MB")
        print(f"å³°å€¼å†…å­˜: {peak_memory:.1f} MB")
        print(f"å†…å­˜å¢é•¿: {memory_increase:.1f} MB")
        
        # æ¸…ç†å†…å­˜
        del large_arrays
        gc.collect()
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_recovered = peak_memory - final_memory
        
        print(f"æ¸…ç†åå†…å­˜: {final_memory:.1f} MB")
        print(f"å›æ”¶å†…å­˜: {memory_recovered:.1f} MB")
        
        # å†…å­˜ä½¿ç”¨åº”è¯¥åˆç† (å¢é•¿ä¸è¶…è¿‡500MB)
        assert memory_increase < 500, f"å†…å­˜ä½¿ç”¨è¿‡å¤š: {memory_increase:.1f} MB"
        
        # å†…å­˜åº”è¯¥èƒ½å¤Ÿå›æ”¶ (è‡³å°‘å›æ”¶50%)
        recovery_rate = memory_recovered / memory_increase if memory_increase > 0 else 1.0
        assert recovery_rate > 0.5, f"å†…å­˜å›æ”¶ä¸è¶³: {recovery_rate*100:.1f}%"
        
    def test_numerical_stability_validation(self):
        """æµ‹è¯•æ•°å€¼ç¨³å®šæ€§éªŒè¯"""
        from core import PhoenixCurveCalculator, SafeCalculator
        
        calc = PhoenixCurveCalculator()
        safe_calc = SafeCalculator()
        
        # æµ‹è¯•æç«¯è¾“å…¥å€¼
        extreme_inputs = [
            np.array([0.0, 1e-10, 1e-8, 1e-6, 0.5, 1.0-1e-6, 1.0-1e-8, 1.0-1e-10, 1.0]),
            np.array([1e-15, 1e-12, 1e-9, 0.1, 0.9, 1.0-1e-9, 1.0-1e-12, 1.0-1e-15]),
        ]
        
        extreme_params = [
            (0.1, 0.0),    # æœ€å°p, æœ€å°a
            (6.0, 1.0),    # æœ€å¤§p, æœ€å¤§a
            (0.1, 1.0),    # æœ€å°p, æœ€å¤§a
            (6.0, 0.0),    # æœ€å¤§p, æœ€å°a
        ]
        
        for L_input in extreme_inputs:
            for p, a in extreme_params:
                try:
                    # ç›´æ¥è®¡ç®—
                    L_out = calc.compute_phoenix_curve(L_input, p, a)
                    
                    # æ£€æŸ¥ç»“æœæœ‰æ•ˆæ€§
                    assert np.all(np.isfinite(L_out)), f"ç»“æœåŒ…å«éæœ‰é™å€¼: p={p}, a={a}"
                    assert np.all(L_out >= 0), f"ç»“æœåŒ…å«è´Ÿå€¼: p={p}, a={a}"
                    assert np.all(L_out <= 1), f"ç»“æœè¶…å‡ºèŒƒå›´: p={p}, a={a}"
                    
                    # æ£€æŸ¥å•è°ƒæ€§
                    is_monotonic = calc.validate_monotonicity(L_out)
                    if not is_monotonic:
                        print(f"è­¦å‘Š: æç«¯å‚æ•°({p}, {a})äº§ç”Ÿéå•è°ƒæ›²çº¿")
                        
                    # å®‰å…¨è®¡ç®—éªŒè¯
                    L_safe, success, msg = safe_calc.safe_phoenix_calculation(L_input, p, a)
                    assert np.all(np.isfinite(L_safe)), f"å®‰å…¨è®¡ç®—ç»“æœåŒ…å«éæœ‰é™å€¼: p={p}, a={a}"
                    
                except Exception as e:
                    pytest.fail(f"æ•°å€¼ç¨³å®šæ€§æµ‹è¯•å¤±è´¥: p={p}, a={a}, é”™è¯¯: {e}")
                    
        print("æ•°å€¼ç¨³å®šæ€§éªŒè¯é€šè¿‡")
        
    def test_edge_cases_comprehensive(self):
        """æµ‹è¯•å…¨é¢çš„è¾¹ç•Œæƒ…å†µ"""
        from core import (PhoenixCurveCalculator, QualityMetricsCalculator, 
                         TemporalSmoothingProcessor, SplineCurveCalculator)
        
        # Phoenixæ›²çº¿è¾¹ç•Œæƒ…å†µ
        calc = PhoenixCurveCalculator()
        
        # ç©ºæ•°ç»„
        empty_array = np.array([])
        try:
            result = calc.compute_phoenix_curve(empty_array, 2.0, 0.5)
            assert len(result) == 0, "ç©ºæ•°ç»„åº”è¯¥è¿”å›ç©ºç»“æœ"
        except Exception:
            pass  # å…è®¸æŠ›å‡ºå¼‚å¸¸
            
        # å•ç‚¹æ•°ç»„
        single_point = np.array([0.5])
        result = calc.compute_phoenix_curve(single_point, 2.0, 0.5)
        assert len(result) == 1, "å•ç‚¹æ•°ç»„åº”è¯¥è¿”å›å•ç‚¹ç»“æœ"
        assert np.isfinite(result[0]), "å•ç‚¹ç»“æœåº”è¯¥æ˜¯æœ‰é™å€¼"
        
        # è´¨é‡æŒ‡æ ‡è¾¹ç•Œæƒ…å†µ
        quality_calc = QualityMetricsCalculator()
        
        # å•åƒç´ å›¾åƒ
        single_pixel = np.array([[0.5]])
        L_in = quality_calc.extract_luminance(single_pixel)
        L_out = L_in.copy()
        
        distortion = quality_calc.compute_perceptual_distortion(L_in, L_out)
        assert np.isfinite(distortion), "å•åƒç´ å¤±çœŸåº”è¯¥æ˜¯æœ‰é™å€¼"
        
        contrast = quality_calc.compute_local_contrast(L_out)
        assert np.isfinite(contrast), "å•åƒç´ å¯¹æ¯”åº¦åº”è¯¥æ˜¯æœ‰é™å€¼"
        
        # æ—¶åŸŸå¹³æ»‘è¾¹ç•Œæƒ…å†µ
        temporal_proc = TemporalSmoothingProcessor(window_size=5)
        
        # ç©ºå†å²
        smoothed = temporal_proc.compute_weighted_average()
        assert smoothed == {}, "ç©ºå†å²åº”è¯¥è¿”å›ç©ºå­—å…¸"
        
        # å•å¸§å†å²
        temporal_proc.add_frame_parameters({"p": 2.0, "a": 0.5}, 0.1)
        smoothed = temporal_proc.compute_weighted_average()
        assert "p" in smoothed, "å•å¸§å†å²åº”è¯¥è¿”å›å‚æ•°"
        assert abs(smoothed["p"] - 2.0) < 1e-10, "å•å¸§å¹³æ»‘åº”è¯¥ç­‰äºåŸå€¼"
        
        print("è¾¹ç•Œæƒ…å†µæµ‹è¯•é€šè¿‡")


def run_comprehensive_regression_tests():
    """è¿è¡Œå…¨é¢çš„å›å½’æµ‹è¯•"""
    print("å¼€å§‹è¿è¡Œå…¨é¢å›å½’æµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•å®ä¾‹
    test_instance = TestRegressionSuite()
    test_instance.setup_class()
    
    try:
        # è¿è¡Œå„é¡¹æµ‹è¯•
        test_methods = [
            "test_golden_standard_phoenix_curves",
            "test_golden_standard_quality_metrics", 
            "test_golden_standard_temporal_smoothing",
            "test_monotonicity_stress_comprehensive",
            "test_hysteresis_stability_comprehensive",
            "test_export_import_consistency_comprehensive",
            "test_full_regression_suite_execution",
            "test_report_generation_and_content",
            "test_performance_benchmarks",
            "test_memory_usage_validation",
            "test_numerical_stability_validation",
            "test_edge_cases_comprehensive"
        ]
        
        passed_tests = 0
        failed_tests = 0
        
        for method_name in test_methods:
            try:
                print(f"\nè¿è¡Œæµ‹è¯•: {method_name}")
                method = getattr(test_instance, method_name)
                method()
                print(f"âœ… {method_name} é€šè¿‡")
                passed_tests += 1
            except Exception as e:
                print(f"âŒ {method_name} å¤±è´¥: {e}")
                failed_tests += 1
                
        # è¾“å‡ºæ€»ç»“
        total_tests = passed_tests + failed_tests
        pass_rate = passed_tests / total_tests * 100 if total_tests > 0 else 0
        
        print(f"\n=== å…¨é¢å›å½’æµ‹è¯•æ€»ç»“ ===")
        print(f"æ€»æµ‹è¯•æ–¹æ³•: {total_tests}")
        print(f"é€šè¿‡: {passed_tests}")
        print(f"å¤±è´¥: {failed_tests}")
        print(f"é€šè¿‡ç‡: {pass_rate:.1f}%")
        
        return pass_rate >= 80  # 80%é€šè¿‡ç‡ä¸ºåˆæ ¼
        
    finally:
        test_instance.teardown_class()


if __name__ == "__main__":
    # è¿è¡Œå…¨é¢å›å½’æµ‹è¯•
    success = run_comprehensive_regression_tests()
    
    if success:
        print("\nğŸ‰ å…¨é¢å›å½’æµ‹è¯•é€šè¿‡!")
        exit(0)
    else:
        print("\nâŒ å…¨é¢å›å½’æµ‹è¯•å¤±è´¥!")
        exit(1)